% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Homework \#2 STA 360},
  pdfauthor={Jerry Xin STA 360: Homework 2},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Homework \#2 STA 360}
\author{Jerry Xin STA 360: Homework 2}
\date{Due Friday September 3rd, 5 PM EDT}

\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(knitr)}
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lab component (30 points total) Please refer to lab 2 and complete
  tasks 3---5.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  \begin{enumerate}
  \def\labelenumii{(\arabic{enumii})}
  \setcounter{enumii}{9}
  \tightlist
  \item
    Task 3
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumii{(\arabic{enumii})}
  \setcounter{enumii}{9}
  \tightlist
  \item
    Task 4
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumii{(\arabic{enumii})}
  \setcounter{enumii}{9}
  \tightlist
  \item
    Task 5
  \end{enumerate}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# set a seed}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\CommentTok{# create the observed data}
\NormalTok{obs.data <-}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(}\DataTypeTok{n =} \DecValTok{100}\NormalTok{, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =} \FloatTok{0.01}\NormalTok{)}
\CommentTok{# inspect the observed data}
\KeywordTok{head}\NormalTok{(obs.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0 0 0 0 0 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tail}\NormalTok{(obs.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0 0 0 0 0 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(obs.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\hypertarget{task-3}{%
\section{Task 3}\label{task-3}}

Write a function that takes as its inputs that data you simulated (or
any data of the same type) and a sequence of \(\theta\) values of length
1000 and produces Likelihood values based on the Binomial Likelihood.
Plot your sequence and its corresponding Likelihood function.

The likelihood function is given below. Since this is a probability and
is only valid over the interval from \([0, 1]\) we generate a sequence
over that interval of length 1000.

You have a rough sketch of what you should do for this part of the
assignment. Try this out in lab on your own.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{### Bernoulli LH Function }\AlertTok{###}

\CommentTok{# Input: obs.data, theta}
\CommentTok{# Output: bernoulli likelihood}

\NormalTok{myBernLH <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(obs.data, theta)\{}
\NormalTok{  N <-}\StringTok{ }\KeywordTok{length}\NormalTok{(obs.data)}
\NormalTok{  x <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(obs.data)}
\NormalTok{  LH <-}\StringTok{ }\NormalTok{(theta}\OperatorTok{^}\NormalTok{x) }\OperatorTok{*}\StringTok{ }\NormalTok{((}\DecValTok{1}\OperatorTok{-}\NormalTok{theta)}\OperatorTok{^}\NormalTok{(N}\OperatorTok{-}\NormalTok{x))}
  \KeywordTok{return}\NormalTok{(LH)}
\NormalTok{\}}


\CommentTok{### Plot LH for a grid of theta values }\AlertTok{###}
\CommentTok{# Create the grid #}
\CommentTok{# Store the LH values}
\CommentTok{# Create the Plot}
\NormalTok{theta.sim <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{0}\NormalTok{, }\DataTypeTok{to =} \DecValTok{1}\NormalTok{, }\DataTypeTok{length.out =} \DecValTok{1000}\NormalTok{)}
\NormalTok{sim.LH <-}\StringTok{ }\KeywordTok{myBernLH}\NormalTok{(obs.data, }\DataTypeTok{theta =}\NormalTok{ theta.sim)}
\KeywordTok{plot}\NormalTok{(theta.sim, sim.LH, }\DataTypeTok{type =}\StringTok{"line"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Likelihood Profile"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Simulated Support"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Likelihood"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{hw-02_files/figure-latex/unnamed-chunk-2-1} \end{center}

\hypertarget{task-4-to-be-completed-for-homework}{%
\section{Task 4 (To be completed for
homework)}\label{task-4-to-be-completed-for-homework}}

Write a function that takes as its inputs prior parameters \textsf{a}
and \textsf{b} for the Beta-Bernoulli model and the observed data, and
produces the posterior parameters you need for the model.
\textbf{Generate and print} the posterior parameters for a
non-informative prior i.e.~\textsf{(a,b) = (1,1)} and for an informative
case \textsf{(a,b) = (3,1)}\}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(priorA, priorB, obs.data)}
\NormalTok{\{}
\NormalTok{  N <-}\StringTok{ }\KeywordTok{length}\NormalTok{(obs.data)}
\NormalTok{  x <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(obs.data)}
\NormalTok{  postA <-}\StringTok{ }\NormalTok{priorA }\OperatorTok{+}\StringTok{ }\NormalTok{x}
\NormalTok{    postB <-}\StringTok{ }\NormalTok{priorB }\OperatorTok{+}\StringTok{ }\NormalTok{N }\OperatorTok{-}\StringTok{ }\NormalTok{x}
\NormalTok{    postparam <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{'postA'}\NormalTok{ =}\StringTok{ }\NormalTok{postA, }
     \StringTok{'postB'}\NormalTok{ =}\StringTok{ }\NormalTok{postB)}
    \KeywordTok{return}\NormalTok{(postparam)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nonInformative <-}\StringTok{ }\KeywordTok{posterior}\NormalTok{(}\DataTypeTok{priorA =} \DecValTok{1}\NormalTok{, }\DataTypeTok{priorB =} \DecValTok{1}\NormalTok{, }\DataTypeTok{obs.data =}\NormalTok{ obs.data)}
\NormalTok{informative <-}\StringTok{ }\KeywordTok{posterior}\NormalTok{(}\DataTypeTok{priorA =} \DecValTok{3}\NormalTok{, }\DataTypeTok{priorB =} \DecValTok{1}\NormalTok{, }\DataTypeTok{obs.data =}\NormalTok{ obs.data)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{c}\NormalTok{(nonInformative, informative))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $postA
## [1] 2
## 
## $postB
## [1] 100
## 
## $postA
## [1] 4
## 
## $postB
## [1] 100
\end{verbatim}

\hypertarget{task-5-to-be-completed-for-homework}{%
\section{Task 5 (To be completed for
homework)}\label{task-5-to-be-completed-for-homework}}

Create two plots, one for the informative and one for the
non-informative case to show the posterior distribution and superimpose
the prior distributions on each along with the likelihood. What do you
see? Remember to turn the y-axis ticks off since superimposing may make
the scale non-sense.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nonInformativeDen <-}\StringTok{ }\KeywordTok{dbeta}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ theta.sim, }\DataTypeTok{shape1 =}\NormalTok{ nonInformative}\OperatorTok{$}\NormalTok{postA, }
 \DataTypeTok{shape2 =}\NormalTok{nonInformative}\OperatorTok{$}\NormalTok{postB)}
\NormalTok{informativeDen <-}\StringTok{ }\KeywordTok{dbeta}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ theta.sim, }\DataTypeTok{shape1 =}\NormalTok{ informative}\OperatorTok{$}\NormalTok{postA, }
 \DataTypeTok{shape2 =}\NormalTok{ informative}\OperatorTok{$}\NormalTok{postB)}
\NormalTok{priorInform <-}\StringTok{ }\KeywordTok{dbeta}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ theta.sim, }\DataTypeTok{shape1 =} \DecValTok{3}\NormalTok{, }
 \DataTypeTok{shape2 =} \DecValTok{1}\NormalTok{)}
\NormalTok{priorNonInform <-}\StringTok{ }\KeywordTok{dbeta}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ theta.sim, }\DataTypeTok{shape1 =} \DecValTok{1}\NormalTok{, }
 \DataTypeTok{shape2 =} \DecValTok{1}\NormalTok{)}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)) }
\KeywordTok{plot}\NormalTok{(theta.sim, sim.LH, }\DataTypeTok{lty =} \DecValTok{2}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{'Simulated Thetas'}\NormalTok{,}
 \DataTypeTok{ylab =} \StringTok{'Density/LH'}\NormalTok{, }\DataTypeTok{type =} \StringTok{'l'}\NormalTok{, }\DataTypeTok{yaxt =} \StringTok{'n'}\NormalTok{, }\DataTypeTok{main =} \StringTok{'Informative'}\NormalTok{,}
\NormalTok{ , }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{))}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{new =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(theta.sim, informativeDen, }\DataTypeTok{lty =} \DecValTok{1}\NormalTok{, }\DataTypeTok{axes =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{''}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{''}\NormalTok{,}
 \DataTypeTok{type =} \StringTok{'l'}\NormalTok{, , }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"green"}\NormalTok{))}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{new =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(theta.sim, priorInform, }\DataTypeTok{lty =} \DecValTok{3}\NormalTok{, }\DataTypeTok{axes =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{''}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{''}\NormalTok{,}
 \DataTypeTok{type =} \StringTok{'l'}\NormalTok{, }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{))}
\KeywordTok{legend}\NormalTok{(}\StringTok{'topright'}\NormalTok{, }\DataTypeTok{lty=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DataTypeTok{legend =} \KeywordTok{c}\NormalTok{(}\StringTok{'LH'}\NormalTok{, }\StringTok{'Posterior'}\NormalTok{, }\StringTok{'Prior'}\NormalTok{),}
       \DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{cex =} \FloatTok{0.5}\NormalTok{)}

\KeywordTok{plot}\NormalTok{(theta.sim, sim.LH, }\DataTypeTok{lty =} \DecValTok{2}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{'Simulated Thetas'}\NormalTok{,}
 \DataTypeTok{ylab =} \StringTok{'Density/LH'}\NormalTok{, }\DataTypeTok{type =} \StringTok{'l'}\NormalTok{, }\DataTypeTok{yaxt =} \StringTok{'n'}\NormalTok{, }\DataTypeTok{main =} \StringTok{'Non-informative'}\NormalTok{, }
 \DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{))}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{new =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(theta.sim, nonInformativeDen, }\DataTypeTok{lty =} \DecValTok{1}\NormalTok{, }\DataTypeTok{axes =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{''}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{''}\NormalTok{,}
 \DataTypeTok{type =} \StringTok{'l'}\NormalTok{, }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"green"}\NormalTok{))}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{new =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(theta.sim, priorNonInform, }\DataTypeTok{lty =} \DecValTok{3}\NormalTok{, }\DataTypeTok{axes =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{''}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{''}\NormalTok{,}
 \DataTypeTok{type =} \StringTok{'l'}\NormalTok{, }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{))}
\KeywordTok{legend}\NormalTok{(}\StringTok{'topright'}\NormalTok{, }\DataTypeTok{lty=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DataTypeTok{legend =} \KeywordTok{c}\NormalTok{(}\StringTok{'LH'}\NormalTok{, }\StringTok{'Posterior'}\NormalTok{, }\StringTok{'Prior'}\NormalTok{), }
       \DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{cex=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{hw-02_files/figure-latex/unnamed-chunk-5-1} \end{center}

These graphs both show the posterior distribution is a result of
combining the Likelihood and the Prior. It is graphically seen as an
average between the Likelihood and Prior. A non-informative prior is
graphically seen as a flat line and seems to have less/ almost neglible
effect on the posterior, as it seems to have no effect on the posterior
graph. The effect is less when compared to a prior which is informative,
which is graphically a upwards sloping curve, and is shown to have a
larger effect on moving the posterior rightwards.

\item

(20 points total) \{\em The Exponential-Gamma Model\} We write
\(X\sim\Exp(\theta)\) to indicate that \(X\) has the Exponential
distribution, that is, its p.d.f.~is
\[ p(x|\theta) =\Exp(x|\theta) = \theta\exp(-\theta x)\I(x>0). \] The
Exponential distribution has some special properties that make it a good
model for certain applications. It has been used to model the time
between events (such as neuron spikes, website hits, neutrinos captured
in a detector), extreme values such as maximum daily rainfall over a
period of one year, or the amount of time until a product fails
(lightbulbs are a standard example).

Suppose you have data \(x_1,\dotsc,x_n\) which you are modeling as
i.i.d.~observations from an Exponential distribution, and suppose that
your prior is \(\btheta\sim\Ga(a,b)\), that is,
\[ p(\theta) = \Ga(\theta|a,b) = \frac{b^a}{\Gamma(a)}\theta^{a-1}\exp(-b\theta) \I(\theta>0).\]
\[\theta^{n}\exp(-\theta \sum{x_i})\frac{b^a}{\Gamma(a)}\theta^{a-1}\exp(-b\theta)\]
Remove \(\frac{b^a}{\Gamma(a)}\) because it doesn't have theta and can
be treated as a constant to get:
\[\theta^{n}\exp(-\theta \sum{x})\theta^{a-1}\exp(-b\theta)\]

Simplify to get: \[\theta^{a + n -1}\exp(-\theta *(b + \sum{x}))\]
\[\Ga(\theta|a+n,b + \sum{x})\] The posterior is a Gamma Distribution
with Gamma(a + n, b + sum(x)).

\begin{enumerate}
\item (5) Derive the formula for the posterior density, $p(\theta|x_{1:n})$. Give the form of the posterior in terms of one of the most common distributions (Bernoulli, Beta, Exponential, or Gamma).

$$\theta^{n}\exp(-\theta \sum{x_i})\frac{b^a}{\Gamma(a)}\theta^{a-1}\exp(-b\theta)$$
Remove $\frac{b^a}{\Gamma(a)}$ because it doesn't have theta and can be treated as a constant to get:
$$\theta^{n}\exp(-\theta \sum{x})\theta^{a-1}\exp(-b\theta)$$
Simplify to get:
$$\theta^{a + n -1}\exp(-\theta *(b + \sum{x}))$$
$$\Ga(\theta|a+n,b + \sum{x})$$
The posterior is a Gamma Distribution with Gamma(a + n, b + sum(x)).

\item (5) Why is the posterior distribution a \emph{proper} density or probability distribution function? \
The posterior distribution is a proper density, or probability distribution function, because it integrates to 1, which means the area under the function adds up to 1.

\item (5) Now, suppose you are measuring the number of seconds between lightning strikes during a storm, your prior is $\Ga(0.1,1.0)$, and your data is
$$(x_1,\dotsc,x_8) = (20.9, 69.7, 3.6, 21.8, 21.4, 0.4, 6.7, 10.0).$$
Plot the prior and posterior p.d.f.s. (Be sure to make your plots on a scale that allows you to clearly see the important features.)


```r
# set a seed
set.seed(123)
# create the observed data
obs.data2 <- c(20.9, 69.7, 3.6, 21.8, 21.4, 0.4, 6.7, 10.0)
# inspect the observed data
head(obs.data2)
```

```
## [1] 20.9 69.7  3.6 21.8 21.4  0.4
```

```r
tail(obs.data2)
```

```
## [1]  3.6 21.8 21.4  0.4  6.7 10.0
```

```r
length(obs.data2)
```

```
## [1] 8
```

```r
posterior2 <- function(priorA, priorB, obs.data)
{
  N <- length(obs.data2)
  x <- sum(obs.data2)
  postA <- priorA + N
    postB <- priorB + x
    postparam <- list('postA' = postA, 
     'postB' = postB)
    return(postparam)
}
```


```r
informative1<- posterior2(priorA = 0.1, priorB = 1.0, obs.data = obs.data2)
print(c(informative))
```

```
## $postA
## [1] 4
## 
## $postB
## [1] 100
```

```r
gamma.sim <- seq(from = 0, to = 1, length.out = 1000)
```

```r
informativeDen1 <- dgamma(x = gamma.sim, shape = informative1$postA, 
 rate = informative1$postB)
priorInform1 <- dgamma(x = gamma.sim, shape = 0.1, 
 rate = 1)

plot(gamma.sim, informativeDen1, lty = 1, xlab = expression(theta), ylab = 'Density',
 type = 'l', , col = c("green"))
par(new = TRUE)
plot(gamma.sim, priorInform1, lty = 3, axes = FALSE, xlab = '', ylab = '',
 type = 'l', col = c("blue"))
legend('topright', lty=c(2,1,3), legend = c( 'Posterior', 'Prior'),
       col = c("green", "blue"), cex = 0.5)
```



\begin{center}\includegraphics{hw-02_files/figure-latex/unnamed-chunk-9-1} \end{center}


\item (5) Give a specific example of an application where an Exponential model would be reasonable. Give an example where an Exponential model would NOT be appropriate, and explain why.
\end{enumerate}

Exponential functions assuming a constant multiplicative rate of change,
so a specific application would be studying a bacteria in a petri dish
that undergoes binary fission(splits into 2 identical replicas). The
constant multiplicative rate of change here would be 2, and would not
change from 2 ever. An example where the exponential model would not be
appropiate is modeling the stock market, as there is not anywhere close
to a constant rate of change in the stock market, which is highly
unpredictable and consists of lots of valleys and peaks, not to mention
recessions and economic stagnation. There is no constant multiplicative
rate of change here.

Constant Rate Assumption with the Exponential Model, time in between
events. Assuming constant time in between events.

\item

(40 points total)
\{\em Priors, Posteriors, Predictive Distributions (Hoff, 3.9)\} An
unknown quantity \(Y\) has a Galenshore(\(a, \theta\)) distribution if
its density is given by
\[p(y) = \frac{2}{\Gamma(a)} \; \theta^{2a} y^{2a - 1} e^{-\theta^2 y^2}\]
for \(y>0, \theta >0, a>0.\) Assume for now that \(a\) is known. For
this density, \[E[Y] = \frac{\Gamma(a +1/2)}{\theta \Gamma(a)}\] and
\[E[Y^2] = \frac{a}{\theta^2}.\]

\textbackslash begin\{enumerate\}

\item

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Identify a class of conjugate prior densities for \(\theta\).
  \textcolor{red}{Assume the prior parameters are $c$ and $d.$} Plot a
  few members of this class of densities.
\end{enumerate}

Let the prior also be a Galenshore(\$c, \$d) distribution:
\[p(\theta) = \frac{2}{\Gamma(c)} \; d^{2c} \theta^{2c - 1} e^{-d^2 \theta^2}\]
The likelihood a Galenshore(\(a, \theta\)) distribution:
\[p(y) = \frac{2}{\Gamma(a)} \; \theta^{2a} y^{2a - 1} e^{-\theta^2 y^2}\]
Because you have \(\theta^{2a}\) , and \(e^{-\theta^2 y^2}\), only a
Galenshore distribution would work as a conjugate prior density.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dgalenshore <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(theta, c, d) \{}
    \CommentTok{# takes numeric vector (elements should be >0) and returns the galenshore}
    \CommentTok{# probability density at each point. Parameters a and theta should all be}
    \CommentTok{# > 0.}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{any}\NormalTok{(theta }\OperatorTok{<=}\StringTok{ }\DecValTok{0}\NormalTok{) }\OperatorTok{||}\StringTok{ }\KeywordTok{any}\NormalTok{(c }\OperatorTok{<=}\StringTok{ }\DecValTok{0}\NormalTok{) }\OperatorTok{||}\StringTok{ }\KeywordTok{any}\NormalTok{(d }\OperatorTok{<=}\StringTok{ }\DecValTok{0}\NormalTok{)) \{}
        \KeywordTok{stop}\NormalTok{(}\StringTok{"Invalid parameters or input values. Inputs must be >0"}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
        \KeywordTok{return}\NormalTok{((}\DecValTok{2}\OperatorTok{/}\KeywordTok{gamma}\NormalTok{(c)) }\OperatorTok{*}\StringTok{ }\NormalTok{d}\OperatorTok{^}\NormalTok{(}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{c) }\OperatorTok{*}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{d}\OperatorTok{^}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{theta}\OperatorTok{^}\DecValTok{2}\NormalTok{))}
\NormalTok{    \}}
\NormalTok{\}}
\NormalTok{x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{3}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(x, }\KeywordTok{dgalenshore}\NormalTok{(x, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Galenshore Density(x)"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"black"}\NormalTok{, }
    \DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{), }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{) }
\KeywordTok{lines}\NormalTok{(x, }\KeywordTok{dgalenshore}\NormalTok{(x, }\DecValTok{1}\NormalTok{, }\FloatTok{1.5}\NormalTok{), }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{, }\DataTypeTok{lty =} \DecValTok{2}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(x, }\KeywordTok{dgalenshore}\NormalTok{(x, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{), }\DataTypeTok{type =} \StringTok{"l"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd =} \DecValTok{2}\NormalTok{, }\DataTypeTok{lty =} \DecValTok{3}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"Galenshore(1,1)"}\NormalTok{, }\StringTok{"Galenshore(1,2)"}\NormalTok{, }\StringTok{"Galenshore(3,1)"}\NormalTok{), }
    \DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{lty =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{hw-02_files/figure-latex/unnamed-chunk-10-1} \end{center}

\item

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Let \(Y_1, \ldots, Y_n \stackrel{iid}{\sim}\)
  Galenshore(\(a, \theta\)). Find the posterior distribution of
  \(\theta \mid y_{1:n}\) using a prior from your conjugate class. You
  have a sample of ys, \(y_{1:n}\) See attached document.
\end{enumerate}

\item

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Write down
  \[\frac{p(\theta_a \mid y_{1:n})}{p(\theta_b \mid y_{1:n})}\] and
  simplify. Identify a sufficient statistic. Compared the ratio of 2
  different likelihood distributions, one has parameter a and one has
  parameter b. Normalizing constants will cancel out, some
  simplification. See Attached document.
\end{enumerate}

\item

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Determine \[E[\theta \mid y_{1:n}]\]. See Attached Document
\end{enumerate}

\item

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Show that the form of the posterior predictive density
  \[p(y_{n+1} \mid y_{1:n}) =  \frac{2 y_{n+1}^{2a - 1} \Gamma(an + a + c)}{\Gamma(a)\Gamma(an + c)}
  \frac{(d^2 + \sum y_i^2)^{an + c}}{(d^2 + \sum y_i^2 + y_{n+1}^2)^{(an + a + c)}}.\]
  See Attached Document.
\end{enumerate}

\end{document}
